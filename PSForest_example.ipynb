{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "\n",
    "\n",
    "from PSForest import PSForest\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:\n",
    "MNIST and CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (70000, 784), target: (70000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")\n",
    "mnist.data.shape\n",
    "\n",
    "print('Data: {}, target: {}'.format(mnist.data.shape, mnist.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1000, 784) float64\n",
      "y_train: (1000,) category\n",
      "X_test: (500, 784)\n",
      "y_test: (500,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mnist.data,\n",
    "    mnist.target,\n",
    "    test_size=1/7,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "X_train = X_train.values.reshape((len(X_train), 784))\n",
    "X_test = X_test.values.reshape((len(X_test), 784))\n",
    "\n",
    "\n",
    "#Limit the size of the dataset\n",
    "\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "X_test = X_test[:500]\n",
    "y_test = y_test[:500]\n",
    "\n",
    "print('X_train:', X_train.shape, X_train.dtype)\n",
    "print('y_train:', y_train.shape, y_train.dtype)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def load_CIFAR_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f,encoding='latin1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    return X, Y\n",
    "def load_CIFAR10():\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join('datasets', 'cifar-10-batches-py', 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join('datasets', 'cifar-10-batches-py', 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_CIFAR10()\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'dear', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "num_each_class = 7\n",
    "\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, num_each_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + (y + 1)\n",
    "        plt.subplot(num_each_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "# Divide the sub-data set\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]\n",
    "X_train = X_train[:1000]\n",
    "X_test = X_test[:1000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the PSForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Cascade fitting for X ((1000, 784)) and y ((1000,)) started\n",
      "<Gate-CascadeForest forests=8> - Level #1:: X with shape: (1000, 784)\n",
      "<Gate-CascadeForest forests=8> - Level 1:: got all predictions\n",
      "<Gate-CascadeForest forests=8> - Level 1:: got accuracy 0.87\n",
      "<Gate-CascadeForest forests=8> - Level #2:: X with shape: (1000, 844)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.876, 0.884, 0.876, 0.881, 0.874, 0.892, 0.864, 0.883]\n",
      "[4, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Level 2:: got all predictions\n",
      "<Gate-CascadeForest forests=8> - Level 2:: got accuracy 0.88\n",
      "<Gate-CascadeForest forests=8> - Level #3:: X with shape: (1000, 904)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88, 0.881, 0.886, 0.881, 0.881, 0.883, 0.891, 0.885]\n",
      "[4, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Level 3:: got all predictions\n",
      "<Gate-CascadeForest forests=8> - Level 3:: got accuracy 0.873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.886, 0.88, 0.886, 0.876, 0.887, 0.88, 0.886, 0.882]\n",
      "[4, 0, 0, 1, 1, 3]\n",
      "Memory (Before): [1854.83984375]Mb\n",
      "Memory (After): [2223.68359375]Mb\n",
      "Memory consumption: 368.84375Mb\n"
     ]
    }
   ],
   "source": [
    "start =time.clock()\n",
    "before_mem = memory_profiler.memory_usage()\n",
    "# Create PSForest model\n",
    "ps_forest = PSForest(\n",
    "    estimators_config={\n",
    "        'mgs': [{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'max_features': 1,\n",
    "                'min_samples_split': 10,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'max_features': 1,\n",
    "                'min_samples_split': 10,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }],\n",
    "        'cascade': [{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "           'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }   \n",
    "        },{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "           'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }   \n",
    "        }]\n",
    "    },\n",
    "    stride_ratios=[1/256,1/128,1/64,1/32,1/16,1/8,1/4],\n",
    ")\n",
    "\n",
    "# ps_forest.fit(X_train, y_train)   # with Multi-Grained Pooling\n",
    "ps_forest.fit_c(X_train, y_train)  # without Multi-Grained Pooling\n",
    "after_mem = memory_profiler.memory_usage()\n",
    "end = time.clock()\n",
    "print(\"Memory (Before): {}Mb\".format(before_mem))\n",
    "print(\"Memory (After): {}Mb\".format(after_mem))\n",
    "print(\"Memory consumption: {}Mb\".format(after_mem[0] - before_mem[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<MultiGrainedScanner stride_ratio=0.00390625> - Scanning and fitting for X ((500, 784)) and y (None) started\n",
      "<MultiGrainedScanner stride_ratio=0.00390625> - Window shape: [3] Total windows: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 8)\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8848c7606e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# with Multi-Grained Pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# y_pred = ps_forest.predict_c(X_test)   # without Multi-Grained Pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PSForest/PSForest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     71\u001b[0m         scanned_X = np.hstack([\n\u001b[1;32m     72\u001b[0m             \u001b[0mmgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmgs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgs_instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         ])\n\u001b[1;32m     75\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 原始X转化为一维\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PSForest/PSForest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m         scanned_X = np.hstack([\n\u001b[1;32m     72\u001b[0m             \u001b[0mmgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmgs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgs_instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         ])\n\u001b[1;32m     75\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 原始X转化为一维\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PSForest/PSForest.py\u001b[0m in \u001b[0;36mscan\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction with estimator #{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliced_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 self.logger.debug(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \"\"\"\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred = ps_forest.predict(X_test)  # with Multi-Grained Pooling\n",
    "# y_pred = ps_forest.predict_c(X_test)   # without Multi-Grained Pooling\n",
    "print('Prediction shape:', y_pred.shape)\n",
    "print(\n",
    "    'Accuracy:', accuracy_score(y_test, y_pred),\n",
    "    'F1 score:', f1_score(y_test, y_pred, average='weighted')\n",
    ")\n",
    "\n",
    "print('Running time: %s Seconds'%(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.898\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test,  rf_y_pred)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
