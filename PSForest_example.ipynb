{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import uuid\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "\n",
    "\n",
    "from PSForest import PSForest\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:\n",
    "MNIST and CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (70000, 784), target: (70000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")\n",
    "mnist.data.shape\n",
    "\n",
    "print('Data: {}, target: {}'.format(mnist.data.shape, mnist.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1000, 784) float64\n",
      "y_train: (1000,) category\n",
      "X_test: (500, 784)\n",
      "y_test: (500,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mnist.data,\n",
    "    mnist.target,\n",
    "    test_size=1/7,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "X_train = X_train.values.reshape((len(X_train), 784))\n",
    "X_test = X_test.values.reshape((len(X_test), 784))\n",
    "\n",
    "\n",
    "#Limit the size of the dataset\n",
    "\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]\n",
    "X_test = X_test[:500]\n",
    "y_test = y_test[:500]\n",
    "\n",
    "print('X_train:', X_train.shape, X_train.dtype)\n",
    "print('y_train:', y_train.shape, y_train.dtype)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_test:', y_test.shape)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def load_CIFAR_batch(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f,encoding='latin1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "        Y = np.array(Y)\n",
    "    return X, Y\n",
    "def load_CIFAR10():\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join('datasets', 'cifar-10-batches-py', 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)    \n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join('datasets', 'cifar-10-batches-py', 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_CIFAR10()\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'dear', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "num_each_class = 7\n",
    "\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, num_each_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + (y + 1)\n",
    "        plt.subplot(num_each_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "# Divide the sub-data set\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]\n",
    "X_train = X_train[:1000]\n",
    "X_test = X_test[:1000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the PSForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Cascade fitting for X ((1000, 784)) and y ((1000,)) started\n",
      "<Gate-CascadeForest forests=8> - Level #1:: X with shape: (1000, 784)\n",
      "<Gate-CascadeForest forests=8> - Level 1:: got all predictions\n",
      "<Gate-CascadeForest forests=8> - Level 1:: got accuracy 0.87\n",
      "<Gate-CascadeForest forests=8> - Level #2:: X with shape: (1000, 844)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.876, 0.884, 0.876, 0.881, 0.874, 0.892, 0.864, 0.883]\n",
      "[4, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Level 2:: got all predictions\n",
      "<Gate-CascadeForest forests=8> - Level 2:: got accuracy 0.88\n",
      "<Gate-CascadeForest forests=8> - Level #3:: X with shape: (1000, 904)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88, 0.881, 0.886, 0.881, 0.881, 0.883, 0.891, 0.885]\n",
      "[4, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Level 3:: got all predictions\n",
      "<Gate-CascadeForest forests=8> - Level 3:: got accuracy 0.873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.886, 0.88, 0.886, 0.876, 0.887, 0.88, 0.886, 0.882]\n",
      "[4, 0, 0, 1, 1, 3]\n",
      "Memory (Before): [1854.83984375]Mb\n",
      "Memory (After): [2223.68359375]Mb\n",
      "Memory consumption: 368.84375Mb\n"
     ]
    }
   ],
   "source": [
    "start =time.clock()\n",
    "before_mem = memory_profiler.memory_usage()\n",
    "# Create PSForest model\n",
    "ps_forest = PSForest(\n",
    "    estimators_config={\n",
    "        'mgs': [{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'max_features': 1,\n",
    "                'min_samples_split': 10,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'max_features': 1,\n",
    "                'min_samples_split': 10,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        },{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }],\n",
    "        'cascade': [{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "           'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }   \n",
    "        },{\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "           'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 1,\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }\n",
    "        }, {\n",
    "            'estimator_class': RandomForestClassifier,\n",
    "            'estimator_params': {\n",
    "                'n_estimators': 500,\n",
    "                'min_samples_split': 10,\n",
    "                'max_features': 'sqrt',\n",
    "                'oob_score':True,\n",
    "                'n_jobs': -1,\n",
    "            }   \n",
    "        }]\n",
    "    },\n",
    "    stride_ratios=[1/256,1/128,1/64,1/32,1/16,1/8,1/4],\n",
    ")\n",
    "\n",
    "# ps_forest.fit(X_train, y_train)   # with Multi-Grained Pooling\n",
    "ps_forest.fit_c(X_train, y_train)  # without Multi-Grained Pooling\n",
    "after_mem = memory_profiler.memory_usage()\n",
    "end = time.clock()\n",
    "print(\"Memory (Before): {}Mb\".format(before_mem))\n",
    "print(\"Memory (After): {}Mb\".format(after_mem))\n",
    "print(\"Memory consumption: {}Mb\".format(after_mem[0] - before_mem[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Shape of predictions: (8, 500, 10) shape of X: (500, 784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.876, 0.884, 0.876, 0.881, 0.874, 0.892, 0.864, 0.883]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<Gate-CascadeForest forests=8> - Shape of predictions: (8, 500, 10) shape of X: (500, 844)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88, 0.881, 0.886, 0.881, 0.881, 0.883, 0.891, 0.885]\n",
      "Prediction shape: (500,)\n",
      "Accuracy: 0.91 F1 score: 0.9089381150872761\n",
      "Running time: 46.042792000000006 Seconds\n"
     ]
    }
   ],
   "source": [
    "# y_pred = ps_forest.predict(X_test)  # with Multi-Grained Pooling\n",
    "y_pred = ps_forest.predict_c(X_test)   # without Multi-Grained Pooling\n",
    "print('Prediction shape:', y_pred.shape)\n",
    "print(\n",
    "    'Accuracy:', accuracy_score(y_test, y_pred),\n",
    "    'F1 score:', f1_score(y_test, y_pred, average='weighted')\n",
    ")\n",
    "\n",
    "print('Running time: %s Seconds'%(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.896\n"
     ]
    }
   ],
   "source": [
    "# RandomForest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test,  rf_y_pred)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
